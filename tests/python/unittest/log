[13:48:54] /ssd2/liuchao52/tvm/src/tir/schedule/concrete_schedule.cc:553: Warning: dddd bind
[13:48:54] /ssd2/liuchao52/tvm/src/tir/schedule/concrete_schedule.cc:553: Warning: dddd bind
[13:48:54] /ssd2/liuchao52/tvm/src/tir/schedule/concrete_schedule.cc:553: Warning: dddd bind
[13:48:54] /ssd2/liuchao52/tvm/src/tir/schedule/concrete_schedule.cc:553: Warning: dddd bind
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: sequential
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InjectPrefetch
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InjectPrefetch
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block("reduce"):
                            vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                            T.reads(A[vi, vj, vk, vl])
                            T.writes(B[vi, vj, vk])
                            with T.init():
                                B[vi, vj, vk] = T.float32(0)
                            B[vi, vj, vk] = B[vi, vj, vk] + A[vi, vj, vk, vl]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.TextureFlatten
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.TextureFlatten
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block("reduce"):
                            vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                            T.reads(A[vi, vj, vk, vl])
                            T.writes(B[vi, vj, vk])
                            with T.init():
                                B[vi, vj, vk] = T.float32(0)
                            B[vi, vj, vk] = B[vi, vj, vk] + A[vi, vj, vk, vl]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.StorageFlatten
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.StorageFlatten
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block("reduce"):
                            vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                            T.reads(A[vi, vj, vk, vl])
                            T.writes(B[vi, vj, vk])
                            with T.init():
                                B[vi, vj, vk] = T.float32(0)
                            B[vi, vj, vk] = B[vi, vj, vk] + A[vi, vj, vk, vl]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerCrossThreadReduction
[13:48:54] /ssd2/liuchao52/tvm/src/tir/transforms/lower_cross_thread_reduction.cc:902: Warning: 6clc# from tvm.script import tir as T

@T.prim_func
def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
    T.func_attr({"tir.noalias": T.bool(True)})
    # with T.block("root"):
    for i in T.thread_binding(1, thread="blockIdx.x"):
        for j in T.thread_binding(1, thread="threadIdx.z"):
            for k in T.thread_binding(1, thread="threadIdx.y"):
                for l in T.thread_binding(4, thread="threadIdx.x"):
                    with T.block("reduce"):
                        vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                        T.reads(A[vi, vj, vk, vl])
                        T.writes(B[vi, vj, vk])
                        with T.init():
                            B[vi, vj, vk] = T.float32(0)
                        B[vi, vj, vk] = B[vi, vj, vk] + A[vi, vj, vk, vl]
[13:48:54] /ssd2/liuchao52/tvm/src/tir/transforms/lower_cross_thread_reduction.cc:904: Warning: # from tvm.script import tir as T

@T.prim_func
def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
    T.func_attr({"tir.noalias": T.bool(True)})
    # with T.block("root"):
    cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
    for i in T.thread_binding(1, thread="blockIdx.x"):
        for j in T.thread_binding(1, thread="threadIdx.z"):
            for k in T.thread_binding(1, thread="threadIdx.y"):
                for l in T.thread_binding(4, thread="threadIdx.x"):
                    with T.block("reduce_cross_thread"):
                        vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                        T.reads(A[vi, vj, vk, vl])
                        T.writes(cross_thread_B[0])
                        T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                        T.tvm_thread_allreduce(T.uint32(1), A[vi, vj, vk, vl], T.bool(True), cross_thread_B[0], l)
                    with T.block("reduce_write_back"):
                        vi, vj, vk = T.axis.remap("SSS", [i, j, k])
                        T.where(l == 0)
                        T.reads(cross_thread_B[0])
                        T.writes(B[vi, vj, vk])
                        B[vi, vj, vk] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerCrossThreadReduction
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block("reduce_cross_thread"):
                            vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                            T.reads(A[vi, vj, vk, vl])
                            T.writes(cross_thread_B[0])
                            T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                            T.tvm_thread_allreduce(T.uint32(1), A[vi, vj, vk, vl], T.bool(True), cross_thread_B[0], l)
                        with T.block("reduce_write_back"):
                            vi, vj, vk = T.axis.remap("SSS", [i, j, k])
                            T.where(l == 0)
                            T.reads(cross_thread_B[0])
                            T.writes(B[vi, vj, vk])
                            B[vi, vj, vk] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerInitBlock
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerInitBlock
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block("reduce_cross_thread"):
                            vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                            T.reads(A[vi, vj, vk, vl])
                            T.writes(cross_thread_B[0])
                            T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                            T.tvm_thread_allreduce(T.uint32(1), A[vi, vj, vk, vl], T.bool(True), cross_thread_B[0], l)
                        with T.block("reduce_write_back"):
                            vi, vj, vk = T.axis.remap("SSS", [i, j, k])
                            T.where(l == 0)
                            T.reads(cross_thread_B[0])
                            T.writes(B[vi, vj, vk])
                            B[vi, vj, vk] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.PlanAndUpdateBufferAllocationLocation
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.PlanAndUpdateBufferAllocationLocation
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[i, j, k, l])
                            T.writes(B[i, j, k])
                            cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                                T.reads(A[vi, vj, vk, vl])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[vi, vj, vk, vl], T.bool(True), cross_thread_B[0], l)
                            with T.block("reduce_write_back"):
                                vi, vj, vk = T.axis.remap("SSS", [i, j, k])
                                T.where(l == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[vi, vj, vk])
                                B[vi, vj, vk] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.ConvertBlocksToOpaque
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.ConvertBlocksToOpaque
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i in T.thread_binding(1, thread="blockIdx.x"):
            for j in T.thread_binding(1, thread="threadIdx.z"):
                for k in T.thread_binding(1, thread="threadIdx.y"):
                    for l in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[i, j, k, l])
                            T.writes(B[i, j, k])
                            cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[i, j, k, l])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[i, j, k, l], T.bool(True), cross_thread_B[0], l)
                            with T.block("reduce_write_back"):
                                T.where(l == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[i, j, k])
                                B[i, j, k] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LiftThreadBinding
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LiftThreadBinding
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                            T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                            cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                                B[blockIdx_x, threadIdx_z, threadIdx_y] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.ManifestSharedMemoryLocalStage
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.ManifestSharedMemoryLocalStage
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                            T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                            cross_thread_B = T.alloc_buffer((1,), strides=(1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                                B[blockIdx_x, threadIdx_z, threadIdx_y] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.CompactBufferAllocation
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.CompactBufferAllocation
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                            T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                                B[blockIdx_x, threadIdx_z, threadIdx_y] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerAutoCopy
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerAutoCopy
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                            T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                                B[blockIdx_x, threadIdx_z, threadIdx_y] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.UnifyThreadBinding
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.UnifyThreadBinding
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                            T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                                B[blockIdx_x, threadIdx_z, threadIdx_y] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerMatchBuffer
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerMatchBuffer
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                            T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[blockIdx_x, threadIdx_z, threadIdx_y, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[blockIdx_x, threadIdx_z, threadIdx_y])
                                B[blockIdx_x, threadIdx_z, threadIdx_y] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[0, 0, 0, threadIdx_x])
                            T.writes(B[0, 0, 0])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[0, 0, 0, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[0, 0, 0, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[0, 0, 0])
                                B[0, 0, 0] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InjectPermutedLayout
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InjectPermutedLayout
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[0, 0, 0, threadIdx_x])
                            T.writes(B[0, 0, 0])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[0, 0, 0, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[0, 0, 0, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[0, 0, 0])
                                B[0, 0, 0] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[0, 0, 0, threadIdx_x])
                            T.writes(B[0, 0, 0])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[0, 0, 0, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[0, 0, 0, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[0, 0, 0])
                                B[0, 0, 0] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InjectSoftwarePipeline
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InjectSoftwarePipeline
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[0, 0, 0, threadIdx_x])
                            T.writes(B[0, 0, 0])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[0, 0, 0, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[0, 0, 0, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[0, 0, 0])
                                B[0, 0, 0] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.TransformMmaBufferLayout
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.TransformMmaBufferLayout
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for blockIdx_x in T.thread_binding(1, thread="blockIdx.x"):
            for threadIdx_z in T.thread_binding(1, thread="threadIdx.z"):
                for threadIdx_y in T.thread_binding(1, thread="threadIdx.y"):
                    for threadIdx_x in T.thread_binding(4, thread="threadIdx.x"):
                        with T.block(""):
                            T.reads(A[0, 0, 0, threadIdx_x])
                            T.writes(B[0, 0, 0])
                            cross_thread_B = T.alloc_buffer((1,), scope="local")
                            with T.block("reduce_cross_thread"):
                                T.reads(A[0, 0, 0, threadIdx_x])
                                T.writes(cross_thread_B[0])
                                T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
                                T.tvm_thread_allreduce(T.uint32(1), A[0, 0, 0, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
                            with T.block("reduce_write_back"):
                                T.where(threadIdx_x == 0)
                                T.reads(cross_thread_B[0])
                                T.writes(B[0, 0, 0])
                                B[0, 0, 0] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerOpaqueBlock
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerOpaqueBlock
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.decl_buffer((1,), scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            T.tvm_thread_allreduce(T.uint32(1), A[0, 0, 0, threadIdx_x], T.bool(True), cross_thread_B[0], threadIdx_x)
        if threadIdx_x == 0:
            B[0, 0, 0] = cross_thread_B[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.FlattenBuffer
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.FlattenBuffer
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.FP8ComputeLegalize
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.FP8ComputeLegalize
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.BF16ComputeLegalize
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.BF16ComputeLegalize
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.NarrowDataType
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.NarrowDataType
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LoopPartition
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LoopPartition
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.VectorizeLoop
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.VectorizeLoop
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InjectVirtualThread
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InjectVirtualThread
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InjectDoubleBuffer
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InjectDoubleBuffer
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B = T.allocate([1], "float32", "local")
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.StorageRewrite
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.StorageRewrite
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.UnrollLoop
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.UnrollLoop
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.RenormalizeSplitPattern
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.RenormalizeSplitPattern
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.RemoveNoOp
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.RemoveNoOp
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.RewriteUnsafeSelect
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.RewriteUnsafeSelect
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.HoistIfThenElse
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InsertHoistIfThenElse
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InsertHoistIfThenElse
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Simplify
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.RemoveNoOp
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.RemoveNoOp
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.HoistIfThenElse
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.CommonSubexprElimTIR
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.CommonSubexprElimTIR
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: sequential
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/driver/driver_api.cc:416: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: sequential
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.calculate_allocated_bytes
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.calculate_allocated_bytes
[13:48:54] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerVtcmAlloc
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerVtcmAlloc
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.BindTarget
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.BindTarget
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.VerifyMemory
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.VerifyMemory
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.AnnotateEntryFunc
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.AnnotateEntryFunc
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.ThreadSync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.ThreadSync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.ThreadSync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.ThreadSync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.MergeDynamicSharedMemoryAllocations
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.MergeDynamicSharedMemoryAllocations
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.ThreadSync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.ThreadSync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.InferFragment
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.InferFragment
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerThreadAllreduce
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerThreadAllreduce
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A.data)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.AnnotateDeviceRegions
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.AnnotateDeviceRegions
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        T.attr(T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "target", 0)
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A.data)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.SplitHostDevice
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.ConvertSSA
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.ConvertSSA
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        Module.default_function_kernel(A.data, B.data)

    @T.prim_func(private=True)
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.SplitHostDevice
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        Module.default_function_kernel(A.data, B.data)

    @T.prim_func(private=True)
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.MakePackedAPI
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.MakePackedAPI
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            Module.default_function_kernel(A, B)
        T.ret(0)

    @T.prim_func(private=True)
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.FP8StorageLegalize
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.FP8StorageLegalize
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            Module.default_function_kernel(A, B)
        T.ret(0)

    @T.prim_func(private=True)
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.BF16StorageLegalize
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.BF16StorageLegalize
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            Module.default_function_kernel(A, B)
        T.ret(0)

    @T.prim_func(private=True)
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerDeviceKernelLaunch
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerDeviceKernelLaunch
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.call_packed("default_function_kernel", A, B, 1, 1, 1, 4)
        T.ret(0)

    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: sequential
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.call_packed("default_function_kernel", A, B, 1, 1, 1, 4)
        T.ret(0)

    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/driver/driver_api.cc:418: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.call_packed("default_function_kernel", A, B, 1, 1, 1, 4)
        T.ret(0)

    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: sequential
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Filter
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Filter
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.call_packed("default_function_kernel", A, B, 1, 1, 1, 4)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.BindTarget
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.BindTarget
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        T.attr("default", "device_id", dev_id)
        T.attr("default", "device_type", 2)
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.call_packed("__tvm_set_device", 2, dev_id)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.call_packed("default_function_kernel", A, B, 1, 1, 1, 4)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerTVMBuiltin
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerTVMBuiltin
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerCustomDatatypes
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerCustomDatatypes
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerIntrin
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerIntrin
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerDeviceStorageAccessInfo
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerDeviceStorageAccessInfo
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.CombineContextCall
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.CombineContextCall
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: sequential
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: sequential
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Filter
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Filter
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.BindTarget
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.BindTarget
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerWarpMemory
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerWarpMemory
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.Simplify
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.Simplify
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerCustomDatatypes
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerCustomDatatypes
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerDeviceStorageAccessInfo
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerDeviceStorageAccessInfo
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tvm_warp_activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 2, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tvm_warp_shuffle_down(mask_1[0], red_buf0_1[0], 1, 32, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tvm_warp_shuffle(mask_1[0], red_buf0_1[0], 0, 32, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:266: Warning: 6clc apply pass: tir.LowerIntrin
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: tir.LowerIntrin
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__activemask
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_sync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tir.cuda.__activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tir.cuda.__shfl_sync(mask_1[0], red_buf0_1[0], 0, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:278: Warning: sequential
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__activemask
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_sync
[13:48:55] /ssd2/liuchao52/tvm/src/ir/transform.cc:279: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tir.cuda.__activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tir.cuda.__shfl_sync(mask_1[0], red_buf0_1[0], 0, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__activemask
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_sync
[13:48:55] /ssd2/liuchao52/tvm/src/driver/driver_api.cc:423: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tir.cuda.__activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tir.cuda.__shfl_sync(mask_1[0], red_buf0_1[0], 0, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/driver/driver_api.cc:500: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function(args: T.handle, arg_type_ids: T.handle("int32"), num_args: T.int32, out_ret_value: T.handle("void"), out_ret_tcode: T.handle("int32"), resource_handle: T.handle) -> T.int32:
        T.func_attr({"calling_conv": 1, "target": T.target({"keys": ["cpu"], "kind": "llvm", "tag": ""}), "tir.is_entry_func": T.bool(True), "tir.noalias": T.bool(True)})
        stack_tcode: T.handle("int32") = T.tvm_stack_alloca("arg_tcode", 7)
        stack_tcode_1 = T.decl_buffer((T.uint64(7),), "int32", data=stack_tcode)
        stack_value: T.handle = T.tvm_stack_alloca("arg_value", 7)
        assert num_args == 2, "default_function: num_args should be 2"
        arg_type_ids_1 = T.decl_buffer((2,), "int32", data=arg_type_ids)
        a_code: T.int32 = arg_type_ids_1[0]
        b_code: T.int32 = arg_type_ids_1[1]
        a: T.handle = T.tvm_struct_get(args, 0, 12, "handle")
        b: T.handle = T.tvm_struct_get(args, 1, 12, "handle")
        A: T.handle("float32", "global") = T.tvm_struct_get(a, 0, 1, "handle")
        T.attr(A, "storage_alignment", 64)
        default_function_a_shape: T.handle("int64") = T.tvm_struct_get(a, 0, 2, "handle")
        default_function_a_shape_1 = T.decl_buffer((4,), "int64", data=default_function_a_shape)
        default_function_a_strides: T.handle("int64") = T.tvm_struct_get(a, 0, 3, "handle")
        default_function_a_strides_1 = T.decl_buffer((0,), "int64", data=default_function_a_strides)
        dev_id: T.int32 = T.tvm_struct_get(a, 0, 9, "int32")
        B: T.handle("float32", "global") = T.tvm_struct_get(b, 0, 1, "handle")
        T.attr(B, "storage_alignment", 64)
        default_function_b_shape: T.handle("int64") = T.tvm_struct_get(b, 0, 2, "handle")
        default_function_b_shape_1 = T.decl_buffer((3,), "int64", data=default_function_b_shape)
        default_function_b_strides: T.handle("int64") = T.tvm_struct_get(b, 0, 3, "handle")
        default_function_b_strides_1 = T.decl_buffer((0,), "int64", data=default_function_b_strides)
        assert a_code == 3 or a_code == 13 or a_code == 7 or a_code == 4, "default_function: Expect arg[0] to be pointer"
        assert b_code == 3 or b_code == 13 or b_code == 7 or b_code == 4, "default_function: Expect arg[1] to be pointer"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert 4 == T.tvm_struct_get(a, 0, 4, "int32"), "default_function.a.ndim is expected to equal 4"
        assert T.tvm_struct_get(a, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(a, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(a, 0, 7, "uint16") == T.uint16(1), "default_function.a.dtype is expected to be float32"
        assert T.Cast("int32", default_function_a_shape_1[0]) == 1, "Argument default_function.a.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[0])"
        assert T.Cast("int32", default_function_a_shape_1[1]) == 1, "Argument default_function.a.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[1])"
        assert T.Cast("int32", default_function_a_shape_1[2]) == 1, "Argument default_function.a.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_a_shape[2])"
        assert T.Cast("int32", default_function_a_shape_1[3]) == 4, "Argument default_function.a.shape[3] has an unsatisfied constraint: 4 == T.Cast(\"int32\", default_function_a_shape[3])"
        if not T.isnullptr(default_function_a_strides):
            assert 1 == T.Cast("int32", default_function_a_strides_1[3]), "default_function.a.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(a, 0, 8, "uint64"), "Argument default_function.a.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(a, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(a, 0, 10, "int32") == 2, "Argument default_function.a.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(a, 0, 10, \"int32\")"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert 3 == T.tvm_struct_get(b, 0, 4, "int32"), "default_function.b.ndim is expected to equal 3"
        assert T.tvm_struct_get(b, 0, 5, "uint8") == T.uint8(2) and T.tvm_struct_get(b, 0, 6, "uint8") == T.uint8(32) and T.tvm_struct_get(b, 0, 7, "uint16") == T.uint16(1), "default_function.b.dtype is expected to be float32"
        assert T.Cast("int32", default_function_b_shape_1[0]) == 1, "Argument default_function.b.shape[0] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[0])"
        assert T.Cast("int32", default_function_b_shape_1[1]) == 1, "Argument default_function.b.shape[1] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[1])"
        assert T.Cast("int32", default_function_b_shape_1[2]) == 1, "Argument default_function.b.shape[2] has an unsatisfied constraint: 1 == T.Cast(\"int32\", default_function_b_shape[2])"
        if not T.isnullptr(default_function_b_strides):
            assert T.bool(True), "default_function.b.strides: expected to be compact array"
            T.evaluate(0)
        assert T.uint64(0) == T.tvm_struct_get(b, 0, 8, "uint64"), "Argument default_function.b.byte_offset has an unsatisfied constraint: T.uint64(0) == T.tvm_struct_get(b, 0, 8, \"uint64\")"
        assert T.tvm_struct_get(b, 0, 10, "int32") == 2, "Argument default_function.b.device_type has an unsatisfied constraint: 2 == T.tvm_struct_get(b, 0, 10, \"int32\")"
        assert dev_id == T.tvm_struct_get(b, 0, 9, "int32"), "Argument default_function.b.device_id has an unsatisfied constraint: dev_id == T.tvm_struct_get(b, 0, 9, \"int32\")"
        A_1 = T.decl_buffer((1, 1, 1, 4), data=A)
        B_1 = T.decl_buffer((1, 1, 1), data=B)
        T.tvm_struct_set(stack_value, 0, 12, T.Cast("int64", 2))
        stack_tcode_1[0] = 0
        T.tvm_struct_set(stack_value, 1, 12, T.Cast("int64", dev_id))
        stack_tcode_1[1] = 0
        T.call_packed_lowered("__tvm_set_device", stack_value, stack_tcode, 0, 2)
        with T.attr(0, "compute_scope", "default_function_compute_"):
            T.tvm_struct_set(stack_value, 0, 12, A)
            if T.isnullptr(A):
                stack_tcode_1[0] = 4
            else:
                stack_tcode_1[0] = 3
            T.tvm_struct_set(stack_value, 1, 12, B)
            if T.isnullptr(B):
                stack_tcode_1[1] = 4
            else:
                stack_tcode_1[1] = 3
            T.tvm_struct_set(stack_value, 2, 12, T.Cast("int64", 1))
            stack_tcode_1[2] = 0
            T.tvm_struct_set(stack_value, 3, 12, T.Cast("int64", 1))
            stack_tcode_1[3] = 0
            T.tvm_struct_set(stack_value, 4, 12, T.Cast("int64", 1))
            stack_tcode_1[4] = 0
            T.tvm_struct_set(stack_value, 5, 12, T.Cast("int64", 4))
            stack_tcode_1[5] = 0
            T.call_packed_lowered("default_function_kernel", stack_value, stack_tcode, 0, 6)
        T.ret(0)
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__activemask
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_down_sync
[13:48:55] /ssd2/liuchao52/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.cuda.__shfl_sync
[13:48:55] /ssd2/liuchao52/tvm/src/driver/driver_api.cc:501: Warning: # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    I.module_attrs({"runtime": None})
    @T.prim_func
    def default_function_kernel(A: T.handle("float32", "global"), B: T.handle("float32", "global")):
        T.func_attr({"calling_conv": 2, "target": T.target({"arch": "sm_80", "host": {"keys": ["cpu"], "kind": "llvm", "tag": ""}, "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.kernel_launch_params": ["blockIdx.x", "threadIdx.z", "threadIdx.y", "threadIdx.x"], "tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        red_buf0 = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        red_buf0_1 = T.Buffer((1,), data=red_buf0, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            mask = T.allocate([1], "uint32", "local")
            t0 = T.allocate([1], "float32", "local")
            A_1 = T.Buffer((4,), data=A)
            red_buf0_1[0] = A_1[threadIdx_x]
            mask_1 = T.Buffer((1,), "uint32", data=mask, scope="local")
            mask_1[0] = T.tir.cuda.__activemask()
            t0_1 = T.Buffer((1,), data=t0, scope="local")
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            t0_1[0] = T.tir.cuda.__shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32)
            red_buf0_1[0] = red_buf0_1[0] + t0_1[0]
            red_buf0_1[0] = T.tir.cuda.__shfl_sync(mask_1[0], red_buf0_1[0], 0, 32)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B)
            B_1[0] = red_buf0_1[0]
[13:48:55] /ssd2/liuchao52/tvm/src/target/opt/build_cuda_on.cc:144: Warning: 
#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 700)
#define __shfl_sync(mask, var, lane, width) \
        __shfl((var), (lane), (width))

#define __shfl_down_sync(mask, var, offset, width) \
        __shfl_down((var), (offset), (width))

#define __shfl_up_sync(mask, var, offset, width) \
        __shfl_up((var), (offset), (width))
#endif


#if (((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 4)) || \
     (__CUDACC_VER_MAJOR__ > 11))
#define TVM_ENABLE_L2_PREFETCH 1
#else
#define TVM_ENABLE_L2_PREFETCH 0
#endif

#ifdef _WIN32
  using uint = unsigned int;
  using uchar = unsigned char;
  using ushort = unsigned short;
  using int64_t = long long;
  using uint64_t = unsigned long long;
#else
  #define uint unsigned int
  #define uchar unsigned char
  #define ushort unsigned short
  #define int64_t long long
  #define uint64_t unsigned long long
#endif
extern "C" __global__ void __launch_bounds__(4) default_function_kernel(float* __restrict__ A, float* __restrict__ B) {
  float red_buf0[1];
  uint mask[1];
  float t0[1];
  red_buf0[0] = A[((int)threadIdx.x)];
  mask[0] = __activemask();
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);
  red_buf0[0] = (red_buf0[0] + t0[0]);
  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], 0, 32);
  if (((int)threadIdx.x) == 0) {
    B[0] = red_buf0[0];
  }
}


Module 6clc
FunctionDef 6clc
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f0641a6cfa0>
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f06419f5430>
For 6clc
With 6clc
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f06419fe460>
With 6clc
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Constant object at 0x7f0641a04130>
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.BinOp object at 0x7f0641a04340>
Module 6clc
FunctionDef 6clc
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f0641a0ebe0>
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f0641a0ee20>
For 6clc
With 6clc
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f0641a140a0>
With 6clc
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f0641a14bb0>
Assign 6clc
6clc  <tvm.script.parser.core.doc_core.Call object at 0x7f0641a170a0>
3.8.10 (default, May 26 2023, 14:05:08) 
[GCC 9.4.0]
58208
6clc 132 PrimFunc
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def default_function(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        blockIdx_x = T.launch_thread("blockIdx.x", 1)
        cross_thread_B = T.allocate([1], "float32", "local")
        threadIdx_z = T.launch_thread("threadIdx.z", 1)
        threadIdx_y = T.launch_thread("threadIdx.y", 1)
        threadIdx_x = T.launch_thread("threadIdx.x", 4)
        cross_thread_B_1 = T.Buffer((1,), data=cross_thread_B, scope="local")
        with T.attr(T.comm_reducer(lambda x0, y0: x0 + y0, [T.float32(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0))):
            A_1 = T.Buffer((4,), data=A.data)
            T.tvm_thread_allreduce(T.uint32(1), A_1[threadIdx_x], T.bool(True), cross_thread_B_1[0], threadIdx_x)
        if threadIdx_x == 0:
            B_1 = T.Buffer((1,), data=B.data)
            B_1[0] = cross_thread_B_1[0] xxx yy zz
# from tvm.script import tir as T

@T.prim_func
def reduce(A: T.Buffer((1, 1, 1, 4), "float32"), B: T.Buffer((1, 1, 1), "float32")):
    # with T.block("root"):
    for i in T.thread_binding(1, thread="blockIdx.x"):
        for j in T.thread_binding(1, thread="threadIdx.z"):
            for k in T.thread_binding(1, thread="threadIdx.y"):
                for l in T.thread_binding(4, thread="threadIdx.x"):
                    with T.block("reduce"):
                        vi, vj, vk, vl = T.axis.remap("SSSR", [i, j, k, l])
                        T.reads(A[vi, vj, vk, vl])
                        T.writes(B[vi, vj, vk])
                        with T.init():
                            B[vi, vj, vk] = T.float32(0)
                        B[vi, vj, vk] = B[vi, vj, vk] + A[vi, vj, vk, vl]
